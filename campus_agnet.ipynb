{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "662a3d45-62a6-42b3-9ff6-636394e22288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Loading FAISS indexes and data from storage...\n",
      "ğŸ« Welcome to the University Campus Chatbot! Type 'exit' to stop.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Search by course name, location, or campus:  rajkori\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Search Results:\n",
      "\n",
      "    ğŸ“ **DSEU Rajokri Campus**\n",
      "    ğŸ“ **Campus Name**: DSEU Rajokri Campus\n",
      "    ğŸ“§ **Email**: sunita.k.chaurasia@dseu.ac.in\n",
      "    ğŸ“Œ **Location**: Near Shiv Mandir Rajokri\n",
      "    ğŸ“š **Courses Offered**: Diploma in Computer Engineering, Diploma in Artificial Intelligence & Machine Learning, Bachelor in Computer Application, B.Sc in Data Analytics \n",
      "    ğŸ›ï¸ **Labs & Descriptions**: 6 Computer Labs, 1 Hardware/Electronics Lab, 1 Electrical Workshop\n",
      "    ğŸ“¸ **Campus Photos**: https://drive.google.com/open?id=1_qa0ByLO4rw_803RlEPV6-4LpaK27Qgh\n",
      "    â„¹ï¸ **Additional Data**: N/A\n",
      "    \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Search by course name, location, or campus:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‘‹ Goodbye! Have a great day.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import numpy as np\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# âœ… Load Data\n",
    "data_path = \"ProcessedData/Campuses Data (Responses)(1).xlsx\"\n",
    "df1 = pd.read_excel(data_path)\n",
    "\n",
    "# âœ… Normalize campus names for better search\n",
    "df1[\"Normalized Campus Name\"] = df1[\"Name of the Campus\"].str.replace(r\"\\bDSEU\\b\", \"\", regex=True, case=False).str.strip()\n",
    "\n",
    "# âœ… Select the problematic column name\n",
    "labs_col = \"Labs In the Campus(Provide Labs' description with Labs' name including the departments they fall in)\"\n",
    "\n",
    "# âœ… Initialize Hugging Face Embeddings (Improved Model)\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\")\n",
    "\n",
    "# âœ… Paths for FAISS indexes and pickle storage\n",
    "index_paths = {\n",
    "    \"campus\": \"faiss_campus.index\",\n",
    "    \"course\": \"faiss_course.index\",\n",
    "    \"location\": \"faiss_location.index\",\n",
    "}\n",
    "pickle_path = \"campus_data.pkl\"\n",
    "\n",
    "# âœ… Function to create FAISS index\n",
    "def create_faiss_index(vectors):\n",
    "    dimension = vectors.shape[1]\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(vectors)\n",
    "    return index\n",
    "\n",
    "# âœ… Check if FAISS indexes already exist\n",
    "if all(os.path.exists(path) for path in index_paths.values()) and os.path.exists(pickle_path):\n",
    "    print(\"ğŸ”„ Loading FAISS indexes and data from storage...\")\n",
    "    \n",
    "    # Load FAISS indexes\n",
    "    faiss_campus = faiss.read_index(index_paths[\"campus\"])\n",
    "    faiss_course = faiss.read_index(index_paths[\"course\"])\n",
    "    faiss_location = faiss.read_index(index_paths[\"location\"])\n",
    "    \n",
    "    # Load DataFrame with stored vectors\n",
    "    with open(pickle_path, \"rb\") as f:\n",
    "        df1 = pickle.load(f)\n",
    "else:\n",
    "    print(\"ğŸ“Œ Generating new FAISS indexes and storing data...\")\n",
    "\n",
    "    # Compute vector embeddings\n",
    "    df1[\"Campus Vector\"] = df1[\"Normalized Campus Name\"].apply(lambda x: embedding_model.encode(x))\n",
    "    df1[\"Course Vector\"] = df1[\"Courses Offered by the Campus\"].fillna(\"\").apply(lambda x: embedding_model.encode(x))\n",
    "    df1[\"Location Vector\"] = df1[\"Location of the campus\"].fillna(\"\").apply(lambda x: embedding_model.encode(x))\n",
    "\n",
    "    # Stack vectors into NumPy arrays\n",
    "    campus_vectors = np.stack(df1[\"Campus Vector\"].values)\n",
    "    course_vectors = np.stack(df1[\"Course Vector\"].values)\n",
    "    location_vectors = np.stack(df1[\"Location Vector\"].values)\n",
    "\n",
    "    # Create FAISS indexes\n",
    "    faiss_campus = create_faiss_index(campus_vectors)\n",
    "    faiss_course = create_faiss_index(course_vectors)\n",
    "    faiss_location = create_faiss_index(location_vectors)\n",
    "\n",
    "    # Save FAISS indexes to files\n",
    "    faiss.write_index(faiss_campus, index_paths[\"campus\"])\n",
    "    faiss.write_index(faiss_course, index_paths[\"course\"])\n",
    "    faiss.write_index(faiss_location, index_paths[\"location\"])\n",
    "\n",
    "    # Save DataFrame with vectors to a pickle file\n",
    "    with open(pickle_path, \"wb\") as f:\n",
    "        pickle.dump(df1, f)\n",
    "\n",
    "# âœ… Function to format output\n",
    "def format_output(row):\n",
    "    return f\"\"\"\n",
    "    ğŸ“ **{row.get('Name of the Campus', 'Unknown Campus')}**\n",
    "    ğŸ“ **Campus Name**: {row.get('Name of the Campus', 'N/A')}\n",
    "    ğŸ“§ **Email**: {row.get('Email Address', 'N/A')}\n",
    "    ğŸ“Œ **Location**: {row.get('Location of the campus', 'N/A')}\n",
    "    ğŸ“š **Courses Offered**: {row.get('Courses Offered by the Campus', 'N/A')}\n",
    "    ğŸ›ï¸ **Labs & Descriptions**: {row.get(labs_col, 'N/A')}\n",
    "    ğŸ“¸ **Campus Photos**: {row.get('Upload the Photos of the Campus', 'N/A')}\n",
    "    â„¹ï¸ **Additional Data**: {row.get('Any other Data', 'N/A')}\n",
    "    \"\"\"\n",
    "\n",
    "# âœ… Function to search using FAISS\n",
    "def search_campus(query, faiss_index, vector_column, df, top_k=1):\n",
    "    query_vector = embedding_model.encode(query).reshape(1, -1)\n",
    "    D, I = faiss_index.search(query_vector, k=top_k)  # Retrieve top-k matches\n",
    "    results = []\n",
    "\n",
    "    for idx in I[0]:\n",
    "        if idx == -1:\n",
    "            continue\n",
    "        row = df.iloc[idx]\n",
    "        results.append(format_output(row))\n",
    "\n",
    "    return results if results else [\"âš ï¸ No matching results found!\"]\n",
    "\n",
    "# âœ… Enhanced Function to Handle Multi-Query Search\n",
    "def search_university(query):\n",
    "    query = query.lower().strip()\n",
    "\n",
    "    # ğŸ” **Check for course-related search**\n",
    "    if \"course\" in query:\n",
    "        match = re.search(r\"course (.+)\", query)\n",
    "        if match:\n",
    "            course_query = match.group(1).strip()\n",
    "            return search_campus(course_query, faiss_course, \"Course Vector\", df1)\n",
    "\n",
    "    # ğŸ” **Check for location-related search**\n",
    "    if \"location\" in query:\n",
    "        match = re.search(r\"location (.+)\", query)\n",
    "        if match:\n",
    "            location_query = match.group(1).strip()\n",
    "            return search_campus(location_query, faiss_location, \"Location Vector\", df1)\n",
    "\n",
    "    # ğŸ” **Default: Search by Campus Name**\n",
    "    return search_campus(query, faiss_campus, \"Campus Vector\", df1)\n",
    "\n",
    "# âœ… Initialize LangChain Memory for Chat History\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# âœ… Main Chatbot Loop\n",
    "print(\"ğŸ« Welcome to the University Campus Chatbot! Type 'exit' to stop.\")\n",
    "\n",
    "while True:\n",
    "    user_query = input(\"\\nSearch by course name, location, or campus: \")\n",
    "    \n",
    "    if user_query.lower() == \"exit\":\n",
    "        print(\"ğŸ‘‹ Goodbye! Have a great day.\")\n",
    "        break\n",
    "    \n",
    "    # Store conversation in memory\n",
    "    memory.chat_memory.add_user_message(user_query)\n",
    "    \n",
    "    # Get search results (returns multiple matches)\n",
    "    responses = search_university(user_query)\n",
    "    \n",
    "    # Store bot response in memory\n",
    "    for response in responses:\n",
    "        memory.chat_memory.add_ai_message(response)\n",
    "        print(f\"\\nğŸ” Search Results:\\n{response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02f1692-8709-43fc-bb87-cb206218dcaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
