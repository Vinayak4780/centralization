{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fdbfb51-7062-466d-9acd-6cd3a792d533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéì Welcome to the Faculty Search Chatbot! Type 'exit' to stop.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Search faculty by name, email, department, or designation:  electrical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Search Results:\n",
      "\n",
      "    üë§ **Name**: Jagvir\n",
      "    üìß **Email**: jagvir.singh@dseu.ac.in\n",
      "    üè¢ **Department**: Department of Electrical Engineering\n",
      "    üè∑Ô∏è **Designation**: Associate Professor\n",
      "    \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Search faculty by name, email, department, or designation:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëã Goodbye! Have a great day.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from thefuzz import process  # Import fuzzy matching\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# ‚úÖ Create and Store FAISS Index\n",
    "FAISS_INDEX_PATH = \"faiss_index_faculty_data\"\n",
    "\n",
    "if not os.path.exists(FAISS_INDEX_PATH):\n",
    "    print(f\"‚ö†Ô∏è FAISS index not found at {FAISS_INDEX_PATH}, creating a new one...\")\n",
    "    df = pd.read_excel(\"ProcessedData/findig_mail.xlsx\")\n",
    "    df[\"Normalized Name\"] = df[\"firstName\"].str.lower().str.strip()\n",
    "    df[\"Normalized Email\"] = df[\"email\"].str.lower().str.strip()\n",
    "    df[\"Normalized Department\"] = df[\"organizationUnit\"].str.lower().str.strip()\n",
    "    df[\"Normalized Designation\"] = df[\"designation\"].str.lower().str.strip()\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en\")\n",
    "    vectorstore = FAISS.from_texts(df[\"Normalized Name\"].tolist() + df[\"Normalized Email\"].tolist() + df[\"Normalized Department\"].tolist() + df[\"Normalized Designation\"].tolist(), embeddings)\n",
    "    vectorstore.save_local(FAISS_INDEX_PATH)\n",
    "    print(\"‚úÖ FAISS index created and saved successfully.\")\n",
    "else:\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en\")\n",
    "    vectorstore = FAISS.load_local(\n",
    "        FAISS_INDEX_PATH,\n",
    "        embeddings,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})  # üîπ FAISS optimized retrieval\n",
    "\n",
    "# ‚úÖ Load Faculty Data\n",
    "df = pd.read_excel(\"ProcessedData/findig_mail.xlsx\")\n",
    "df[\"Normalized Name\"] = df[\"firstName\"].str.lower().str.strip()\n",
    "df[\"Normalized Email\"] = df[\"email\"].str.lower().str.strip()\n",
    "df[\"Normalized Department\"] = df[\"organizationUnit\"].str.lower().str.strip()\n",
    "df[\"Normalized Designation\"] = df[\"designation\"].str.lower().str.strip()\n",
    "\n",
    "# ‚úÖ Function to Format Output\n",
    "def format_output(row):\n",
    "    return f\"\"\"\n",
    "    üë§ **Name**: {row.get('firstName', 'Unknown')}\n",
    "    üìß **Email**: {row.get('email', 'N/A')}\n",
    "    üè¢ **Department**: {row.get('organizationUnit', 'N/A') if pd.notna(row.get('organizationUnit')) else 'N/A'}\n",
    "    üè∑Ô∏è **Designation**: {row.get('designation', 'N/A') if pd.notna(row.get('designation')) else 'N/A'}\n",
    "    \"\"\"\n",
    "\n",
    "# ‚úÖ Function to Search Faculty Data\n",
    "def search_faculty(query, df):\n",
    "    query = query.lower().strip()\n",
    "\n",
    "    # ‚úÖ Step 1: Exact Match - Search by Name, Email, Department, or Designation\n",
    "    exact_match_df = df[(df[\"Normalized Name\"] == query) | (df[\"Normalized Email\"] == query) | (df[\"Normalized Department\"] == query) | (df[\"Normalized Designation\"] == query)]\n",
    "    if not exact_match_df.empty:\n",
    "        row = exact_match_df.iloc[0]\n",
    "        return format_output(row)\n",
    "\n",
    "    # ‚úÖ Step 2: If No Exact Match, Use FAISS for Retrieval\n",
    "    faiss_results = retriever.invoke(query)\n",
    "    if faiss_results:\n",
    "        for doc in faiss_results:\n",
    "            faculty_name = doc.page_content.strip()\n",
    "            row = df[(df['Normalized Name'].str.contains(faculty_name, case=False, na=False)) |\n",
    "                     (df['Normalized Email'].str.contains(faculty_name, case=False, na=False)) |\n",
    "                     (df['Normalized Department'].str.contains(faculty_name, case=False, na=False)) |\n",
    "                     (df['Normalized Designation'].str.contains(faculty_name, case=False, na=False))]\n",
    "            if not row.empty:\n",
    "                return format_output(row.iloc[0])\n",
    "\n",
    "    # ‚úÖ Step 3: If No FAISS Results, Use Fuzzy Matching\n",
    "    for column in [\"Normalized Name\", \"Normalized Email\", \"Normalized Department\", \"Normalized Designation\"]:\n",
    "        best_match, score = process.extractOne(query, df[column].unique())\n",
    "        if best_match and score > 75:\n",
    "            fuzzy_match_df = df[df[column].str.contains(best_match, na=False)]\n",
    "            row = fuzzy_match_df.iloc[0]\n",
    "            return format_output(row)\n",
    "\n",
    "    return \"‚ö†Ô∏è No faculty found matching your query!\"\n",
    "\n",
    "# ‚úÖ CLI Chatbot Loop\n",
    "print(\"üéì Welcome to the Faculty Search Chatbot! Type 'exit' to stop.\")\n",
    "while True:\n",
    "    user_query = input(\"\\nSearch faculty by name, email, department, or designation: \")\n",
    "    if user_query.lower() == \"exit\":\n",
    "        print(\"üëã Goodbye! Have a great day.\")\n",
    "        break\n",
    "    response = search_faculty(user_query, df)\n",
    "    print(f\"\\nüîç Search Results:\\n{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39ac127-0349-4725-8be9-6c320af96563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
